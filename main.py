from google.cloud import firestore
from google.cloud import storage, vision
from wand.image import Image

PREFIX = "thumbnail"
client = storage.Client()
vision_client = vision.ImageAnnotatorClient()

def make_thumbnail(data, context):

    # don't do this with thumbnails generated by this function
    if data['name'].startswith(PREFIX):
        return

    newName = f"{PREFIX}-{data['name']}"
    # this is the id of the item in firestore - image name without .jpg
    oldName = data['name'][:-4]
    size = 280

    # Get the bucket which the image has been uploaded to
    bucket = client.get_bucket(data['bucket'])
    # get the image
    thumbnail = Image(blob=bucket.get_blob(data['name']).download_as_string())

    # only resize if it's bigger than our maximum size
    if size < thumbnail.width:
        print('resizing image ' + oldName)
        newHeight = int((size * thumbnail.height) / thumbnail.width)
        thumbnail.resize(size, newHeight)
    
    # resized or not, this is theo ne we need to check for inappropriate content
    thumbnail_blob = bucket.blob(newName)

    safe = __check_image(data)

    if safe:
        thumbnail_blob.upload_from_string(thumbnail.make_blob())
    else:
        print('Replacing inappropriate image with default No Image jpg')
        replacement = Image(blob=bucket.get_blob('NoImage.jpg').download_as_string()) 
        thumbnail_blob.upload_from_string(replacement.make_blob())  

    # make the approved thumbnail public
    thumbnail_blob.make_public()  

    print('updating firestore document with name of approved image')
    happenings = firestore.Client().collection('happenings')
    doc = happenings.document(oldName).get().to_dict()
    doc['image'] = newName[:-4]
    happenings.document(oldName).set(doc)

def __check_image(file_data):
    file_name = file_data['name']
    bucket_name = file_data['bucket']
    blob_uri = f'gs://{bucket_name}/{file_name}'
    blob_source = {'source': {'image_uri': blob_uri}}

    print(f'Analyzing {file_name} in vision API.')

    result = vision_client.safe_search_detection(blob_source)
    detected = result.safe_search_annotation

    if detected.adult == 5 or detected.violence == 5:
        print(f'The image {file_name} was detected as inappropriate.')
        return False
    else:
        print(f'The image {file_name} was detected as OK.')
        return True